{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example how to build an LSTM language model with keras.\n",
    "* Based on: http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
    "* We'll use a different set of parameters and data to make this managable on a CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Embedding, Dropout, TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from IPython.display import SVG\n",
    "from keras_sequential_ascii import sequential_model_to_ascii_printout\n",
    "from keras.callbacks import History \n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_plot(history, validation=True, figsize_=(20,10)):\n",
    "    \"\"\"Plot network metric history for traning and validation sets\"\"\"\n",
    "    df = pd.DataFrame(history.history)\n",
    "    num_epochs = df.shape[0]\n",
    "    \n",
    "    # Set figure size option\n",
    "    # plt.rcParams['figure.figsize'] = figsize_\n",
    "    # Why do I need to reset this everytime?\n",
    "    plt.style.use('dark_background')\n",
    "    plt.figure(figsize=figsize_)\n",
    "    metrics_ = [x for x in df.columns.tolist() if 'val' not in x]\n",
    "    num_metrics = len(metrics_)\n",
    "    \n",
    "    for i in range(0, num_metrics):\n",
    "        plt.subplot(int(round(num_metrics/2)), 2, i+1)\n",
    "        plt.plot(df[metrics_[i]].values, 'r')\n",
    "        if validation:\n",
    "            validation_metric = 'val_' + metrics_[i]\n",
    "            plt.plot(df[validation_metric].values, 'g')\n",
    "        plt.xticks(np.arange(0, num_epochs+1, 1.0))\n",
    "        plt.xlabel(\"Num of Epochs\")\n",
    "        plt.ylabel(metrics_[i])\n",
    "        plt.title(\"Training {0} vs Validation {1}\".format(metrics_[i], metrics_[i]))\n",
    "        plt.legend(['train','validation'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion_matrix(classifier_, x_test, y_test, figsize_=(20,10)):\n",
    "    \"\"\"Make a confusion matrix\"\"\"\n",
    "    Y_pred = classifier_.predict(x_test)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    \n",
    "    # Compute the confusion matrix and store as a DataFrame\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    df_cm = pd.DataFrame(cm)\n",
    "    \n",
    "    plt.figure(figsize=figsize_)\n",
    "    # Set label font size\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(model):\n",
    "    return SVG(keras.utils.vis_utils.model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_words(filename):\n",
    "    with tf.gfile.GFile(filename, \"r\") as f:\n",
    "        return f.read().decode(\"utf-8\").replace(\"\\n\", \"<eos>\").split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(filename):\n",
    "    \"\"\"A function to build the vocabulary from input data\"\"\"\n",
    "    data = read_words(filename)\n",
    "    \n",
    "    counter = collections.Counter(data)\n",
    "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "    \n",
    "    words, _ = list(zip(*count_pairs))\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "    \n",
    "    return word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary_news(data):\n",
    "    \n",
    "    counter = collections.Counter(data)\n",
    "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "    \n",
    "    words, _ = list(zip(*count_pairs))\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "    \n",
    "    return word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_word_ids(filename, word_to_id):\n",
    "    \"\"\"A function to build the word id representation of each file\"\"\"\n",
    "    data = read_words(filename)\n",
    "    \n",
    "    return [word_to_id[word] for word in data if word in word_to_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_word_ids_news(data, word_to_id):\n",
    "    \"\"\"A function to build the word id representation of each file\"\"\"\n",
    "    \n",
    "    return [word_to_id[word] for word in data if word in word_to_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    # get the data paths\n",
    "    train_path = os.path.join(data_path, \"ptb.train.txt\")\n",
    "    valid_path = os.path.join(data_path, \"ptb.valid.txt\")\n",
    "    test_path = os.path.join(data_path, \"ptb.test.txt\")\n",
    "    \n",
    "    # build the complete vocabulary and get the integer representation\n",
    "    word_to_id = build_vocabulary(train_path)\n",
    "    train_data = file_to_word_ids(train_path, word_to_id)\n",
    "    valid_data = file_to_word_ids(valid_path, word_to_id)\n",
    "    test_data = file_to_word_ids(test_path, word_to_id)\n",
    "    vocabulary = len(word_to_id)\n",
    "    reversed_dictionary = dict(zip(word_to_id.values(), word_to_id.keys()))\n",
    "    \n",
    "    return train_data, valid_data, test_data, vocabulary, reversed_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix up this text loading and cleaning.  We can use the functions we've already written for nlp preprocessing\n",
    "def load_data_news(train_data, valid_data, test_data):\n",
    "    train_data_ = ' '.join(train_data).decode(\"utf-8\").replace(\"\\n\", \"<eos>\").split()\n",
    "    valid_data_ = ' '.join(valid_data).decode(\"utf-8\").replace(\"\\n\", \"<eos>\").split()\n",
    "    test_data_ = ' '.join(test_data).decode(\"utf-8\").replace(\"\\n\", \"<eos>\").split()\n",
    "    \n",
    "    # build the complete vocabulary and get the integer representation\n",
    "    word_to_id = build_vocabulary_news(train_data_)\n",
    "    train_data_ = file_to_word_ids_news(train_data_, word_to_id)\n",
    "    valid_data_ = file_to_word_ids_news(valid_data_, word_to_id)\n",
    "    test_data_ = file_to_word_ids_news(test_data_, word_to_id)\n",
    "    vocabulary = len(word_to_id)\n",
    "    reversed_dictionary = dict(zip(word_to_id.values(), word_to_id.keys()))\n",
    "    \n",
    "    return train_data_, valid_data_, test_data_, vocabulary, reversed_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_text_lstm_network(vocabulary, hidden_size, input_length, num_lstms, dropout_size=None):\n",
    "    \"\"\"Function to assemble basic LSTM architecture to text sequences\"\"\"\n",
    "    # Initialize the sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add an embedding layer. This is the first layer of the input. This takes the input words (integers at this stage), and makes a embedding vectors.\n",
    "    # We need to supply the input dimension.  In this case it's the size of the vocabulary\n",
    "    # Then we need to supply the output dimension we want.  Here, it's the size of the hidden layers (dense layers)\n",
    "    # And then we need to supply the input length, that is the number of steps/words in the sample.\n",
    "    # We'll start with the default embedding initializer, which is uniform.\n",
    "    model.add(Embedding(vocabulary, hidden_size, input_length=num_steps))\n",
    "    \n",
    "    # LSTM layers.  We need to provide the size of the hidden layers (forget gate, tanh, etc) and set return_sequences to True. This will output every output from the LSTM through \n",
    "    # the sequence as opposed to just the last output.\n",
    "    for _ in range(num_lstms):\n",
    "        model.add(LSTM(hidden_size, return_sequences=True))\n",
    "    \n",
    "    # If dropout is required\n",
    "    if dropout_size:\n",
    "        model.add(Dropout(dropout_size))\n",
    "        \n",
    "    # Now add the time distributed layer.  This adds an independent layer for each step in the sequence (or each time step, this is num_steps in this case)\n",
    "    model.add(TimeDistributed(Dense(vocabulary)))\n",
    "    \n",
    "    # The acitivation of the dense time distributed layers will be softmax\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    # Return the model object\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_actual_predicted_words(dummy_iters, data, num_steps, batch_size, vocabulary, skip_step, num_predict, reversed_dictionary, model):\n",
    "    \"\"\"Function to generate text from model\"\"\"\n",
    "    # Setup generator object to get a sample from the text data (the same size is the dummy_iters variable)\n",
    "    example_generator = KerasBatchGenerator(data=data, \n",
    "                                            num_steps=num_steps, \n",
    "                                            batch_size=batch_size, \n",
    "                                            vocabulary=vocabulary, \n",
    "                                            skip_step=skip_step)\n",
    "    \n",
    "    # Iterate over dummy_iters indices in the data to set the starting point\n",
    "    for i in range(dummy_iters):\n",
    "        _ = next(example_generator.generate())\n",
    "    \n",
    "    # Setup the return strings (true vs predicted sequences)\n",
    "    true_sequence = \"Actual sequence: \"\n",
    "    predicted_sequence = \"Predicted sequence: \"\n",
    "    \n",
    "    # num_predict here is the number of words to actually predict, so we need to loop over this number of words in the data\n",
    "    for i in range(num_predict):\n",
    "        data_ = next(example_generator.generate())\n",
    "        prediction = model.predict(data_[0])\n",
    "        # Use the argmax to identify where in the predicted vector, the word indices are largest (these correspond to the predicted words)\n",
    "        predicted_word = np.argmax(prediction[:, num_steps - 1, :])\n",
    "        # Get the true sequence of words for comparison\n",
    "        true_sequence += reversed_dictionary[data[num_steps + dummy_iters + i]] + \" \"\n",
    "        # Get out the predicted words from the reversed dictionary\n",
    "        predicted_sequence += reversed_dictionary[predicted_word] + \" \"\n",
    "    \n",
    "    return true_sequence, predicted_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasBatchGenerator(object):\n",
    "    \"\"\"A class to generate batches of data to use in a Keras LSTM\"\"\"\n",
    "    \n",
    "    def __init__(self, data, num_steps, batch_size, vocabulary, skip_step=5):\n",
    "        self.data = data\n",
    "        # The num_steps variable is the number of words to be feed into the time distributed input layer.\n",
    "        # i.e. it is the set of words the model will learn from to predict the next words in the sequence.\n",
    "        self.num_steps = num_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.vocabulary = vocabulary\n",
    "        \n",
    "        # This is the number of words to be skipped over before the next batch is taken from the data.\n",
    "        self.skip_step = skip_step\n",
    "        \n",
    "        # We need a variable to track the progess of the batches sequentially as we move through the data set.\n",
    "        # Once we reach the end of the data, we need to reset the index counter to zero to restart.\n",
    "        self.current_idx = 0\n",
    "    \n",
    "    \n",
    "    def generate(self):\n",
    "        \"\"\"Generate a batch\"\"\"\n",
    "        x = np.zeros((self.batch_size, self.num_steps))\n",
    "        y = np.zeros((self.batch_size, self.num_steps, self.vocabulary))\n",
    "        while True:\n",
    "            for i in range(self.batch_size):\n",
    "                if self.current_idx + self.num_steps >= len(self.data):\n",
    "                    # In this case, we need to reset the index\n",
    "                    self.current_idx = 0\n",
    "                # Setup the training sample: of size num_steps\n",
    "                x[i, :] = self.data[self.current_idx:self.current_idx + self.num_steps]\n",
    "                # Get the sequence for the target.  It's the next set of words shifted by 1.\n",
    "                # We'll design the model to predict the next word, so we need to increment the index by 1.\n",
    "                temp_y = self.data[self.current_idx + 1: self.current_idx + self.num_steps + 1]\n",
    "                # Convert the target sample to one-hot encoding\n",
    "                y[i, :, :] = to_categorical(temp_y, num_classes=self.vocabulary)\n",
    "                self.current_idx += self.skip_step\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Load the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the Penn Tree Bank dataset to start with.  It's pretty big, so we'll see how well we can handle it on cpu.\n",
    "data_path = \"simple-examples/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data, vocabulary, reversed_dictionary = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9970, 9971, 9972, 9974, 9975]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1132, 93, 358, 5, 329]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[102, 14, 24, 32, 752]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim snack-food ssangyong swapo wachter <eos> pierre <unk> N years old will join the board as a nonexecutive director nov. N <eos> mr. <unk> is chairman of <unk> n.v. the dutch publishing group <eos> rudolph <unk> N years old and former chairman of consolidated gold fields plc was named a nonexecutive director of this british industrial conglomerate <eos> a form of asbestos once used to make kent cigarette filters has caused a high percentage of cancer deaths among a group of\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join([reversed_dictionary[x] for x in train_data[:100]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no it was n't black monday <eos> but while the\n"
     ]
    }
   ],
   "source": [
    "# what? \n",
    "print(\" \".join([reversed_dictionary[x] for x in test_data[:10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "929589"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82430"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73760"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I might want to sample on the training data to make this more managable on my laptop..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative dataset\n",
    "* Use the 20 newsgroup dataset as an alternative. This might be a bit more managable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['sci.space']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroup_train = fetch_20newsgroups(subset='train', categories=cats, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroup_test = fetch_20newsgroups(subset='test', categories=cats, remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroup_train.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroup_test.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "575"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroup_train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroup_train_ = newsgroup_train.data[0:100]\n",
    "newsgroup_valid_ = newsgroup_train.data[100:126]\n",
    "newsgroup_test_ = newsgroup_test.data[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data, vocabulary, reversed_dictionary = load_data_news(train_data=newsgroup_train_, valid_data=newsgroup_valid_, test_data=newsgroup_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18356"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2758"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4782"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7531"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<eos>Any lunar satellite needs fuel to do regular orbit corrections, and when<eos>its fuel runs out it will crash within months. The orbits of the Apollo<eos>motherships changed noticeably during lunar missions lasting only a few<eos>days. It is *possible* that there are stable orbits here and there --<eos>the Moon's gravitational field is poorly mapped -- but we know of none.<eos><eos>Perturbations from Sun and Earth are relatively minor issues at low<eos>altitudes. The big problem is that the Moon's own gravitational field<eos>is quite lumpy due to the irregular distribution of mass within the Moon. <eos>Glad to see Griffin is spending his time on engineering\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join([reversed_dictionary[x] for x in train_data[:100]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 10\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the training data generator class\n",
    "train_data_generator = KerasBatchGenerator(data=train_data, \n",
    "                                           num_steps=num_steps,\n",
    "                                           batch_size=batch_size,\n",
    "                                           vocabulary=vocabulary,\n",
    "                                           skip_step=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the validation data generator class\n",
    "valid_data_generator = KerasBatchGenerator(data=valid_data,\n",
    "                                          num_steps=num_steps,\n",
    "                                          batch_size=batch_size,\n",
    "                                          vocabulary=vocabulary,\n",
    "                                          skip_step=num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The size of the hidden layers in the LSTMs. I.e. this is the number of layers to use in the forget gate, the tanh layer, etc...\n",
    "hidden_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to be careful with the size of the network.  We'll be luck to get anything reasonable on a cpu.  \n",
    "model = make_text_lstm_network(vocabulary=vocabulary, hidden_size=hidden_size, input_length=num_steps, num_lstms=1, dropout_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 10, 10)            75310     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 10, 10)            840       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 10)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 10, 7531)          82841     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 7531)          0         \n",
      "=================================================================\n",
      "Total params: 158,991\n",
      "Trainable params: 158,991\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           OPERATION           DATA DIMENSIONS   WEIGHTS(N)   WEIGHTS(%)\n",
      "\n",
      "               Input   #####          10\n",
      "           Embedding   emb | -------------------     75310    47.0%\n",
      "                       #####     10   10\n",
      "                LSTM   LLLLL -------------------       840     0.0%\n",
      "                tanh   #####     10   10\n",
      "             Dropout    | || -------------------         0     0.0%\n",
      "                       #####     10   10\n",
      "     TimeDistributed   ????? -------------------     82841    52.0%\n",
      "             softmax   #####     10 7531\n"
     ]
    }
   ],
   "source": [
    "# visualize the network architecture\n",
    "sequential_model_to_ascii_printout(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"450pt\" viewBox=\"0.00 0.00 495.79 450.00\" width=\"496pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 446)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-446 491.79,-446 491.79,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 4912988304 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>4912988304</title>\n",
       "<polygon fill=\"none\" points=\"85.1655,-324.5 85.1655,-368.5 402.6245,-368.5 402.6245,-324.5 85.1655,-324.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.2363\" y=\"-342.3\">embedding_3: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"249.3071,-324.5 249.3071,-368.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.1416\" y=\"-353.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"249.3071,-346.5 304.9761,-346.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.1416\" y=\"-331.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"304.9761,-324.5 304.9761,-368.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"353.8003\" y=\"-353.3\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"304.9761,-346.5 402.6245,-346.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"353.8003\" y=\"-331.3\">(None, 10, 10)</text>\n",
       "</g>\n",
       "<!-- 4912988688 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>4912988688</title>\n",
       "<polygon fill=\"none\" points=\"117.814,-243.5 117.814,-287.5 369.9761,-287.5 369.9761,-243.5 117.814,-243.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.2363\" y=\"-261.3\">lstm_3: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"216.6587,-243.5 216.6587,-287.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.4932\" y=\"-272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"216.6587,-265.5 272.3276,-265.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.4932\" y=\"-250.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"272.3276,-243.5 272.3276,-287.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321.1519\" y=\"-272.3\">(None, 10, 10)</text>\n",
       "<polyline fill=\"none\" points=\"272.3276,-265.5 369.9761,-265.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321.1519\" y=\"-250.3\">(None, 10, 10)</text>\n",
       "</g>\n",
       "<!-- 4912988304&#45;&gt;4912988688 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>4912988304-&gt;4912988688</title>\n",
       "<path d=\"M243.895,-324.3664C243.895,-316.1516 243.895,-306.6579 243.895,-297.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"247.3951,-297.6068 243.895,-287.6068 240.3951,-297.6069 247.3951,-297.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4912992016 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>4912992016</title>\n",
       "<polygon fill=\"none\" points=\"103.4346,-162.5 103.4346,-206.5 384.3555,-206.5 384.3555,-162.5 103.4346,-162.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.2363\" y=\"-180.3\">dropout_3: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"231.0381,-162.5 231.0381,-206.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258.8726\" y=\"-191.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"231.0381,-184.5 286.707,-184.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258.8726\" y=\"-169.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"286.707,-162.5 286.707,-206.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"335.5313\" y=\"-191.3\">(None, 10, 10)</text>\n",
       "<polyline fill=\"none\" points=\"286.707,-184.5 384.3555,-184.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"335.5313\" y=\"-169.3\">(None, 10, 10)</text>\n",
       "</g>\n",
       "<!-- 4912988688&#45;&gt;4912992016 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>4912988688-&gt;4912992016</title>\n",
       "<path d=\"M243.895,-243.3664C243.895,-235.1516 243.895,-225.6579 243.895,-216.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"247.3951,-216.6068 243.895,-206.6068 240.3951,-216.6069 247.3951,-216.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4912990736 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>4912990736</title>\n",
       "<polygon fill=\"none\" points=\"0,-81.5 0,-125.5 487.79,-125.5 487.79,-81.5 0,-81.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.2363\" y=\"-99.3\">time_distributed_3(dense_3): TimeDistributed(Dense)</text>\n",
       "<polyline fill=\"none\" points=\"320.4727,-81.5 320.4727,-125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.3071\" y=\"-110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"320.4727,-103.5 376.1416,-103.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.3071\" y=\"-88.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"376.1416,-81.5 376.1416,-125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"431.9658\" y=\"-110.3\">(None, 10, 10)</text>\n",
       "<polyline fill=\"none\" points=\"376.1416,-103.5 487.79,-103.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"431.9658\" y=\"-88.3\">(None, 10, 7531)</text>\n",
       "</g>\n",
       "<!-- 4912992016&#45;&gt;4912990736 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>4912992016-&gt;4912990736</title>\n",
       "<path d=\"M243.895,-162.3664C243.895,-154.1516 243.895,-144.6579 243.895,-135.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"247.3951,-135.6068 243.895,-125.6068 240.3951,-135.6069 247.3951,-135.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4907476240 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>4907476240</title>\n",
       "<polygon fill=\"none\" points=\"84.7759,-.5 84.7759,-44.5 403.0142,-44.5 403.0142,-.5 84.7759,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.2363\" y=\"-18.3\">activation_3: Activation</text>\n",
       "<polyline fill=\"none\" points=\"235.6968,-.5 235.6968,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263.5313\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"235.6968,-22.5 291.3657,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263.5313\" y=\"-7.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"291.3657,-.5 291.3657,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"347.1899\" y=\"-29.3\">(None, 10, 7531)</text>\n",
       "<polyline fill=\"none\" points=\"291.3657,-22.5 403.0142,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"347.1899\" y=\"-7.3\">(None, 10, 7531)</text>\n",
       "</g>\n",
       "<!-- 4912990736&#45;&gt;4907476240 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>4912990736-&gt;4907476240</title>\n",
       "<path d=\"M243.895,-81.3664C243.895,-73.1516 243.895,-63.6579 243.895,-54.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"247.3951,-54.6068 243.895,-44.6068 240.3951,-54.6069 247.3951,-54.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4912988496 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>4912988496</title>\n",
       "<polygon fill=\"none\" points=\"200.895,-405.5 200.895,-441.5 286.895,-441.5 286.895,-405.5 200.895,-405.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243.895\" y=\"-419.3\">4912988496</text>\n",
       "</g>\n",
       "<!-- 4912988496&#45;&gt;4912988304 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>4912988496-&gt;4912988304</title>\n",
       "<path d=\"M243.895,-405.2521C243.895,-397.3888 243.895,-387.9498 243.895,-378.9612\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"247.3951,-378.7376 243.895,-368.7377 240.3951,-378.7377 247.3951,-378.7376\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So this model is pretty massive.  I doubt this will train on my laptop.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='model-{epoch:02d}.hdf5', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before fitting, define the history object for the callbacks.\n",
    "history_lstm = History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll need to be conservative with the number of epochs we train this on.  \n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "183/183 [==============================] - 19s 104ms/step - loss: 8.0285 - categorical_accuracy: 0.0424 - val_loss: 6.6974 - val_categorical_accuracy: 0.0819\n",
      "\n",
      "Epoch 00001: saving model to model-01.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12246e6d0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_data_generator.generate(), \n",
    "                    len(train_data)//(batch_size * num_steps), \n",
    "                    num_epochs, \n",
    "                    validation_data=valid_data_generator.generate(), \n",
    "                    validation_steps=len(valid_data)//(batch_size * num_steps),\n",
    "                    callbacks=[checkpointer, history_lstm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categorical_accuracy': [0.04240437117634249],\n",
       " 'loss': [8.028520584106445],\n",
       " 'val_categorical_accuracy': [0.08185185188496555],\n",
       " 'val_loss': [6.697371783079924]}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_lstm.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oh yeah, this is terrible.  We really need a bigger machine in order to build an even somewhat reasonable model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model output on actual text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a sequence from the training set, how well do we do?\n",
    "true_sequence_train, predicted_sequence_train = compare_actual_predicted_words(dummy_iters=40, \n",
    "                                                                               data=train_data, \n",
    "                                                                               num_steps=num_steps, \n",
    "                                                                               batch_size=1, \n",
    "                                                                               vocabulary=vocabulary, \n",
    "                                                                               skip_step=1, \n",
    "                                                                               num_predict=10, \n",
    "                                                                               reversed_dictionary=reversed_dictionary, \n",
    "                                                                               model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual sequence: poorly mapped -- but we know of none.<eos><eos>Perturbations from Sun \n",
      "Predicted sequence: the the the the the the the the the the \n"
     ]
    }
   ],
   "source": [
    "print(true_sequence_train)\n",
    "print(predicted_sequence_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a sequence from the test set, how well do we do?\n",
    "true_sequence_test, predicted_sequence_test = compare_actual_predicted_words(dummy_iters=40, \n",
    "                                                                             data=test_data, \n",
    "                                                                             num_steps=num_steps, \n",
    "                                                                             batch_size=1, \n",
    "                                                                             vocabulary=vocabulary, \n",
    "                                                                             skip_step=1, \n",
    "                                                                             num_predict=10, \n",
    "                                                                             reversed_dictionary=reversed_dictionary, \n",
    "                                                                             model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual sequence: ago. The volume of had to was smaller than what \n",
      "Predicted sequence: the the the the the the the the the the \n"
     ]
    }
   ],
   "source": [
    "print(true_sequence_test)\n",
    "print(predicted_sequence_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:basic_ml]",
   "language": "python",
   "name": "conda-env-basic_ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
