{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example how to build an LSTM language model with keras.\n",
    "* Based on: http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
    "* We'll use a different set of parameters and data to make this managable on a CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Embedding, Dropout, TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from IPython.display import SVG\n",
    "from keras_sequential_ascii import sequential_model_to_ascii_printout\n",
    "from keras.callbacks import History \n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_plot(history, validation=True, figsize_=(20,10)):\n",
    "    \"\"\"Plot network metric history for traning and validation sets\"\"\"\n",
    "    df = pd.DataFrame(history.history)\n",
    "    num_epochs = df.shape[0]\n",
    "    \n",
    "    # Set figure size option\n",
    "    # plt.rcParams['figure.figsize'] = figsize_\n",
    "    # Why do I need to reset this everytime?\n",
    "    plt.style.use('dark_background')\n",
    "    plt.figure(figsize=figsize_)\n",
    "    metrics_ = [x for x in df.columns.tolist() if 'val' not in x]\n",
    "    num_metrics = len(metrics_)\n",
    "    \n",
    "    for i in range(0, num_metrics):\n",
    "        plt.subplot(int(round(num_metrics/2)), 2, i+1)\n",
    "        plt.plot(df[metrics_[i]].values, 'r')\n",
    "        if validation:\n",
    "            validation_metric = 'val_' + metrics_[i]\n",
    "            plt.plot(df[validation_metric].values, 'g')\n",
    "        plt.xticks(np.arange(0, num_epochs+1, 1.0))\n",
    "        plt.xlabel(\"Num of Epochs\")\n",
    "        plt.ylabel(metrics_[i])\n",
    "        plt.title(\"Training {0} vs Validation {1}\".format(metrics_[i], metrics_[i]))\n",
    "        plt.legend(['train','validation'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion_matrix(classifier_, x_test, y_test, figsize_=(20,10)):\n",
    "    \"\"\"Make a confusion matrix\"\"\"\n",
    "    Y_pred = classifier_.predict(x_test)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    \n",
    "    # Compute the confusion matrix and store as a DataFrame\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    df_cm = pd.DataFrame(cm)\n",
    "    \n",
    "    plt.figure(figsize=figsize_)\n",
    "    # Set label font size\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(model):\n",
    "    return SVG(keras.utils.vis_utils.model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_words(filename):\n",
    "    with tf.gfile.GFile(filename, \"r\") as f:\n",
    "        return f.read().decode(\"utf-8\").replace(\"\\n\", \"<eos>\").split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(filename):\n",
    "    \"\"\"A function to build the vocabulary from input data\"\"\"\n",
    "    data = read_words(filename)\n",
    "    \n",
    "    counter = collections.Counter(data)\n",
    "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "    \n",
    "    words, _ = list(zip(*count_pairs))\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "    \n",
    "    return word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary_news(data):\n",
    "    data.decode(\"utf-8\").replace(\"\\n\", \"<eos>\").split()\n",
    "    \n",
    "    counter = collections.Counter(data)\n",
    "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "    \n",
    "    words, _ = list(zip(*count_pairs))\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "    \n",
    "    return word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_word_ids(filename, word_to_id):\n",
    "    \"\"\"A function to build the word id representation of each file\"\"\"\n",
    "    data = read_words(filename)\n",
    "    \n",
    "    return [word_to_id[word] for word in data if word in word_to_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    # get the data paths\n",
    "    train_path = os.path.join(data_path, \"ptb.train.txt\")\n",
    "    valid_path = os.path.join(data_path, \"ptb.valid.txt\")\n",
    "    test_path = os.path.join(data_path, \"ptb.test.txt\")\n",
    "    \n",
    "    # build the complete vocabulary and get the integer representation\n",
    "    word_to_id = build_vocabulary(train_path)\n",
    "    train_data = file_to_word_ids(train_path, word_to_id)\n",
    "    valid_data = file_to_word_ids(valid_path, word_to_id)\n",
    "    test_data = file_to_word_ids(valid_path, word_to_id)\n",
    "    vocabulary = len(word_to_id)\n",
    "    reversed_dictionary = dict(zip(word_to_id.values(), word_to_id.keys()))\n",
    "    \n",
    "    return train_data, valid_data, test_data, vocabulary, reversed_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasBatchGenerator(object):\n",
    "    \"\"\"A class to generate batches of data to use in a Keras LSTM\"\"\"\n",
    "    \n",
    "    def __init__(self, data, num_steps, batch_size, vocabulary, skip_step=5):\n",
    "        self.data = data\n",
    "        # The num_steps variable is the number of words to be feed into the time distributed input layer.\n",
    "        # i.e. it is the set of words the model will learn from to predict the next words in the sequence.\n",
    "        self.num_steps = num_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.vocabulary = vocabulary\n",
    "        \n",
    "        # This is the number of works to be skipped over before the next batch is taken from the data.\n",
    "        self.skip_step = skip_step\n",
    "        \n",
    "        # We need a variable to track the progess of the batches sequentially as we move through the data set.\n",
    "        # Once we reach the end of the data, we need to reset the index counter to zero to restart.\n",
    "        self.current_idx = 0\n",
    "    \n",
    "    \n",
    "    def generate(self):\n",
    "        \"\"\"Generate a batch\"\"\"\n",
    "        x = np.zeros((self.batch_size, self.num_steps))\n",
    "        y = np.zeros((self.batch_size, self.num_steps, self.vocabulary))\n",
    "        while True:\n",
    "            for i in range(self.batch_size):\n",
    "                if self.current_idx + self.num_steps >= len(self.data):\n",
    "                    # In this case, we need to reset the index\n",
    "                    self.current_idx = 0\n",
    "                # Setup the training sample: of size num_steps\n",
    "                x[i, :] = self.data[self.current_idx:self.current_idx + self.num_steps]\n",
    "                # Get the sequence for the target.  It's the next set of words shifted by 1.\n",
    "                # We'll design the model to predict the next word, so we need to increment the index by 1.\n",
    "                temp_y = self.data[self.current_idx + 1: self.current_idx + self.num_steps + 1]\n",
    "                # Convert the target sample to one-hot encoding\n",
    "                y[i, :, :] = to_categorical(temp_y, num_classes=self.vocabulary)\n",
    "                self.current_idx += self.skip_step\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Load the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the Penn Tree Bank dataset to start with.  It's pretty big, so we'll see how well we can handle it on cpu.\n",
    "data_path = \"simple-examples/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data, vocabulary, reversed_dictionary = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9970, 9971, 9972, 9974, 9975]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1132, 93, 358, 5, 329]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1132, 93, 358, 5, 329]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim snack-food ssangyong swapo wachter <eos> pierre <unk> N years old will join the board as a nonexecutive director nov. N <eos> mr. <unk> is chairman of <unk> n.v. the dutch publishing group <eos> rudolph <unk> N years old and former chairman of consolidated gold fields plc was named a nonexecutive director of this british industrial conglomerate <eos> a form of asbestos once used to make kent cigarette filters has caused a high percentage of cancer deaths among a group of\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join([reversed_dictionary[x] for x in train_data[:100]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consumers may want to move their telephones a little closer\n"
     ]
    }
   ],
   "source": [
    "# what? \n",
    "print(\" \".join([reversed_dictionary[x] for x in test_data[:10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "929589"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73760"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73760"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I might want to sample on the training data to make this more managable on my laptop..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative dataset\n",
    "* Use the 20 newsgroup dataset as an alternative. This might be a bit more managable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['sci.space']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "newsgroup_train = fetch_20newsgroups(subset='train', categories=cats)\n",
    "newsgroup_test = fetch_20newsgroups(subset='test', categories=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroup_train.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroup_test.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1360"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroup_train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_news(train_data, valid_data, test_data):\n",
    "\n",
    "    # build the complete vocabulary and get the integer representation\n",
    "    word_to_id = build_vocabulary_news(train_data)\n",
    "    train_data_ret = file_to_word_ids(train_data, word_to_id)\n",
    "    valid_data_ret = file_to_word_ids(valid_data, word_to_id)\n",
    "    test_data_ret = file_to_word_ids(valid_data, word_to_id)\n",
    "    vocabulary = len(word_to_id)\n",
    "    reversed_dictionary = dict(zip(word_to_id.values(), word_to_id.keys()))\n",
    "    \n",
    "    return train_data_ret, valid_data_ret, test_data_ret, vocabulary, reversed_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 30\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the training data generator class\n",
    "train_data_generator = KerasBatchGenerator(data=train_data, \n",
    "                                           num_steps=num_steps,\n",
    "                                           batch_size=batch_size,\n",
    "                                           vocabulary=vocabulary,\n",
    "                                           skip_step=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the validation data generator class\n",
    "valid_data_generator = KerasBatchGenerator(data=valid_data,\n",
    "                                          num_steps=num_steps,\n",
    "                                          batch_size=batch_size,\n",
    "                                          vocabulary=vocabulary,\n",
    "                                          skip_step=num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The size of the hidden layers in the LSTMs. I.e. this is the number of layers to use in the forget gate, the tanh layer, etc...\n",
    "hidden_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_text_lstm_network(vocabulary, hidden_size, input_length, num_lstms, dropout_size=None):\n",
    "    \"\"\"Function to assemble basic LSTM architecture to text sequences\"\"\"\n",
    "    # Initialize the sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add an embedding layer. This is the first layer of the input. This takes the input words (integers at this stage), and makes a embedding vectors.\n",
    "    # We need to supply the input dimension.  In this case it's the size of the vocabulary\n",
    "    # Then we need to supply the output dimension we want.  Here, it's the size of the hidden layers (dense layers)\n",
    "    # And then we need to supply the input length, that is the number of steps/words in the sample.\n",
    "    # We'll start with the default embedding initializer, which is uniform.\n",
    "    model.add(Embedding(vocabulary, hidden_size, input_length=num_steps))\n",
    "    \n",
    "    # LSTM layers.  We need to provide the size of the hidden layers (forget gate, tanh, etc) and set return_sequences to True. This will output every output from the LSTM through \n",
    "    # the sequence as opposed to just the last output.\n",
    "    for _ in range(num_lstms):\n",
    "        model.add(LSTM(hidden_size, return_sequences=True))\n",
    "    \n",
    "    # If dropout is required\n",
    "    if dropout_size:\n",
    "        model.add(Dropout(dropout_size))\n",
    "        \n",
    "    # Now add the time distributed layer.  This adds an independent layer for each step in the sequence (or each time step, this is num_steps in this case)\n",
    "    model.add(TimeDistributed(Dense(vocabulary)))\n",
    "    \n",
    "    # The acitivation of the dense time distributed layers will be softmax\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    # Return the model object\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to be careful with the size of the network.  We'll be luck to get anything reasonable on a cpu.  \n",
    "model = make_text_lstm_network(vocabulary=vocabulary, hidden_size=hidden_size, input_length=num_steps, num_lstms=1, dropout_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 30, 10)            100000    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 30, 10)            840       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 30, 10)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 30, 10000)         110000    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 30, 10000)         0         \n",
      "=================================================================\n",
      "Total params: 210,840\n",
      "Trainable params: 210,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           OPERATION           DATA DIMENSIONS   WEIGHTS(N)   WEIGHTS(%)\n",
      "\n",
      "               Input   #####          30\n",
      "           Embedding   emb | -------------------    100000    47.0%\n",
      "                       #####     30   10\n",
      "                LSTM   LLLLL -------------------       840     0.0%\n",
      "                tanh   #####     30   10\n",
      "             Dropout    | || -------------------         0     0.0%\n",
      "                       #####     30   10\n",
      "     TimeDistributed   ????? -------------------    110000    52.0%\n",
      "             softmax   #####     30 10000\n"
     ]
    }
   ],
   "source": [
    "# visualize the network architecture\n",
    "sequential_model_to_ascii_printout(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"458pt\" viewBox=\"0.00 0.00 502.79 458.00\" width=\"503pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 454)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-454 498.79,-454 498.79,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 4855304080 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>4855304080</title>\n",
       "<polygon fill=\"none\" points=\"82.4517,-405.5 82.4517,-449.5 412.3384,-449.5 412.3384,-405.5 82.4517,-405.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"181.2363\" y=\"-423.3\">embedding_6_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"280.021,-405.5 280.021,-449.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307.8555\" y=\"-434.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"280.021,-427.5 335.6899,-427.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307.8555\" y=\"-412.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"335.6899,-405.5 335.6899,-449.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"374.0142\" y=\"-434.3\">(None, 30)</text>\n",
       "<polyline fill=\"none\" points=\"335.6899,-427.5 412.3384,-427.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"374.0142\" y=\"-412.3\">(None, 30)</text>\n",
       "</g>\n",
       "<!-- 4904796880 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>4904796880</title>\n",
       "<polygon fill=\"none\" points=\"88.6655,-324.5 88.6655,-368.5 406.1245,-368.5 406.1245,-324.5 88.6655,-324.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.7363\" y=\"-342.3\">embedding_6: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"252.8071,-324.5 252.8071,-368.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"280.6416\" y=\"-353.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"252.8071,-346.5 308.4761,-346.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"280.6416\" y=\"-331.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"308.4761,-324.5 308.4761,-368.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"357.3003\" y=\"-353.3\">(None, 30)</text>\n",
       "<polyline fill=\"none\" points=\"308.4761,-346.5 406.1245,-346.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"357.3003\" y=\"-331.3\">(None, 30, 10)</text>\n",
       "</g>\n",
       "<!-- 4855304080&#45;&gt;4904796880 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>4855304080-&gt;4904796880</title>\n",
       "<path d=\"M247.395,-405.3664C247.395,-397.1516 247.395,-387.6579 247.395,-378.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"250.8951,-378.6068 247.395,-368.6068 243.8951,-378.6069 250.8951,-378.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4918449872 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>4918449872</title>\n",
       "<polygon fill=\"none\" points=\"121.314,-243.5 121.314,-287.5 373.4761,-287.5 373.4761,-243.5 121.314,-243.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.7363\" y=\"-261.3\">lstm_9: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"220.1587,-243.5 220.1587,-287.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247.9932\" y=\"-272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"220.1587,-265.5 275.8276,-265.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247.9932\" y=\"-250.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"275.8276,-243.5 275.8276,-287.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"324.6519\" y=\"-272.3\">(None, 30, 10)</text>\n",
       "<polyline fill=\"none\" points=\"275.8276,-265.5 373.4761,-265.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"324.6519\" y=\"-250.3\">(None, 30, 10)</text>\n",
       "</g>\n",
       "<!-- 4904796880&#45;&gt;4918449872 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>4904796880-&gt;4918449872</title>\n",
       "<path d=\"M247.395,-324.3664C247.395,-316.1516 247.395,-306.6579 247.395,-297.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"250.8951,-297.6068 247.395,-287.6068 243.8951,-297.6069 250.8951,-297.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4913727440 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>4913727440</title>\n",
       "<polygon fill=\"none\" points=\"106.9346,-162.5 106.9346,-206.5 387.8555,-206.5 387.8555,-162.5 106.9346,-162.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.7363\" y=\"-180.3\">dropout_4: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"234.5381,-162.5 234.5381,-206.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262.3726\" y=\"-191.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"234.5381,-184.5 290.207,-184.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262.3726\" y=\"-169.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"290.207,-162.5 290.207,-206.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"339.0313\" y=\"-191.3\">(None, 30, 10)</text>\n",
       "<polyline fill=\"none\" points=\"290.207,-184.5 387.8555,-184.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"339.0313\" y=\"-169.3\">(None, 30, 10)</text>\n",
       "</g>\n",
       "<!-- 4918449872&#45;&gt;4913727440 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>4918449872-&gt;4913727440</title>\n",
       "<path d=\"M247.395,-243.3664C247.395,-235.1516 247.395,-225.6579 247.395,-216.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"250.8951,-216.6068 247.395,-206.6068 243.8951,-216.6069 250.8951,-216.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4913620112 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>4913620112</title>\n",
       "<polygon fill=\"none\" points=\"0,-81.5 0,-125.5 494.79,-125.5 494.79,-81.5 0,-81.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.2363\" y=\"-99.3\">time_distributed_4(dense_4): TimeDistributed(Dense)</text>\n",
       "<polyline fill=\"none\" points=\"320.4727,-81.5 320.4727,-125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.3071\" y=\"-110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"320.4727,-103.5 376.1416,-103.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.3071\" y=\"-88.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"376.1416,-81.5 376.1416,-125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"435.4658\" y=\"-110.3\">(None, 30, 10)</text>\n",
       "<polyline fill=\"none\" points=\"376.1416,-103.5 494.79,-103.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"435.4658\" y=\"-88.3\">(None, 30, 10000)</text>\n",
       "</g>\n",
       "<!-- 4913727440&#45;&gt;4913620112 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>4913727440-&gt;4913620112</title>\n",
       "<path d=\"M247.395,-162.3664C247.395,-154.1516 247.395,-144.6579 247.395,-135.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"250.8951,-135.6068 247.395,-125.6068 243.8951,-135.6069 250.8951,-135.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4855363280 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>4855363280</title>\n",
       "<polygon fill=\"none\" points=\"84.7759,-.5 84.7759,-44.5 410.0142,-44.5 410.0142,-.5 84.7759,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.2363\" y=\"-18.3\">activation_4: Activation</text>\n",
       "<polyline fill=\"none\" points=\"235.6968,-.5 235.6968,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263.5313\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"235.6968,-22.5 291.3657,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263.5313\" y=\"-7.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"291.3657,-.5 291.3657,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"350.6899\" y=\"-29.3\">(None, 30, 10000)</text>\n",
       "<polyline fill=\"none\" points=\"291.3657,-22.5 410.0142,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"350.6899\" y=\"-7.3\">(None, 30, 10000)</text>\n",
       "</g>\n",
       "<!-- 4913620112&#45;&gt;4855363280 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>4913620112-&gt;4855363280</title>\n",
       "<path d=\"M247.395,-81.3664C247.395,-73.1516 247.395,-63.6579 247.395,-54.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"250.8951,-54.6068 247.395,-44.6068 243.8951,-54.6069 250.8951,-54.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So this model is pretty massive.  I doubt this will train on my laptop.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:basic_ml]",
   "language": "python",
   "name": "conda-env-basic_ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
